.. _adv_topics:

고급주제
******************

다루지 않았던 기능들에 대해 설명한다.

.. toctree::
   :maxdepth: 2



Emergency 모드
====================================

STON은 모든 가상호스트가 MemoryBlock을 공유하면서 데이터를 관리하도록 설계되어 있다. 
신규 메모리가 필요한 경우 참조되지 않는 오래된 MemoryBlock을 재사용하여 신규 메모리를 확보한다. 
이 과정을 Memory-Swap이라고 부른다. 
이런 구조를 통해 STON을 장기간 운영하여도 안정성을 확보할 수 있다.

.. figure:: img/faq_emergency1.png
   :align: center
      
   콘텐츠 데이터는 MemoryBlock에 담겨 서비스된다.

위 그림의 우측 상황처럼 모든 MemoryBlock이 사용 중이어서 재사용할 수 있는 MemoryBlock이 
존재하지 않는 상황이 발생할 수 있다. 
이때는 Memory-Swap이 불가능해진다. 
예를 들어 모든 클라이언트가 서로 다른 데이터 영역을 아주 조금씩 다운로드 받거나 
원본서버에서 서로 다른 데이터를 아주 조금씩 전송하는 상황이 동시에 발생하는 경우가 최악이다. 
이런 경우 시스템으로부터 새로운 메모리를 할당받아 STON이 사용하는 것도 방법이다. 
하지만 이런 상황이 지속될 경우 STON의 메모리 사용량이 높아진다. 
메모리 사용량이 과도하게 높아질 경우 시스템 메모리스왑을 발생시키거나 최악의 경우 
OS가 STON을 종료시키는 상황이 발생할 수 있다.

.. note::

   Emergency 모드란 메모리 부족상황이 발생할 경우 임시적으로 신규 MemoryBlock의 할당을 금지시키는 상황을 의미한다.

이는 과다 메모리 사용으로부터 STON을 보호하기 위한 방법이며, 
재사용가능한 MemoryBlock이 충분히 확보되면 자동 해지된다. ::

    <Cache>
        <EmergencyMode>OFF</EmergencyMode>
    </Cache>
    
-  ``<EmergencyMode>``

   - ``OFF (기본)`` 사용하지 않는다.
   
   - ``ON`` 사용한다.

Emergency모드일 때 STON은 다음과 같이 동작합니다.

- 이미 로딩되어 있는 컨텐츠는 정상적으로 서비스된다.
- 바이패스는 정상적으로 이루어진다.
- 로딩되어 있지 않은 컨텐츠에 대해서는 503 service temporarily unavailable로 응답한다. TCP_ERROR상태가 증가한다.
- Idle 클라이언트 소켓을 빠르게 정리한다.
- 신규 컨텐츠를 캐싱할 수 없다.
- TTL이 만료된 컨텐츠를 갱신하지 않는다.
- SNMP의 cache.vhost.status와 XML/JSON통계의 Host.State 값이 "Emergency"로 제공된다.
- Info로그에 Emergency모드로 전환/해제를 다음과 같이 기록한다. ::

    2013-08-07 21:10:42 [WARNING] Emergency mode activated. (Memory overused: +100.23MB)
    ...(생략)...
    2013-08-07 21:10:43 [NOTICE] Emergency mode inactivated.


    
원본서버 분산
====================================

서비스되는 컨텐츠가 수 천만개 이상 되면 모든 컨텐츠를 캐싱하는 것은 거의 불가능할 뿐더러 효율적이지도 못하다. 
캐시서버를 고도화하여 보다 많은 캐싱이 가능하게 할 수도 있겠지만, 경제적이지 못한 방법이다. 
가장 효과적인 방법은 개발단계에서 콘텐츠 도메인을 분리하여 별도의 서버로 구성하는 것이다.

.. figure:: img/faq_distdomain.jpg
   :align: center
      
   멀티 도메인이 서비스 확장에 좋다.
   
(A)와 같이 하나의 도메인으로 서비스를 구성하게 된다면 물리적으로 트래픽을 분산할 방법이 없다. 
이런 경우 (B)처럼 도메인을 나누고 각 도메인마다 별도로 캐시서버를 구성하여 트래픽을 
분산할 수 있는 구조를 가지는 것이 바람직하다.
하지만 도메인 분리가 부적합한 상황도 있다. 

예를 들어 컨텐츠 대비 트래픽이 낮거나 서비스 변경 비용이 너무 높은 경우이다. 
이런 경우 분산캐시가 적절한 대안이 될 수 있다. 
분산캐시는 원본에는 변경을 가하지 않고 캐시서버에서 컨텐츠를 나누어 가지는 방법이다.

.. figure:: img/faq_dist.jpg
   :align: center
      
   나름 유명한 캐시 분산

(C)는 L7 로드밸런서가 사용자 요청을 분석하여 각각의 캐시서버에 약속된 룰로 요청을 분배해주는 방법이다. 
하지만 이 방법의 경우 서비스가 L7장비에 종속되어 추후 증설에 문제가 있다. 
뿐만 아니라 한 HTTP세션으로 여러개의 리소스를 요청할 때 캐싱되지 않은 컨텐츠를 요청받을 확률이 높다. 

(D)는 캐시서버들끼리 서로 인식하여 컨텐츠를 나누어 가지는 방식이다. 
가령 #1이 가지지 못한 컨텐츠는 #2에게서 가져와서 서비스하는 방식이다. 
언뜻 효율적인 방법처럼 보이지만 허점이 있다. 
근본적으로 Topology가 매우 복잡해지므로 서버를 증설할 때마다 내부 트래픽이 매우 높게 발생한다. 
또한 사용자들은 연결된 캐시서버에서 즉각적으로 서비스받지 못하고 다른 캐시서버로부터 
데이터를 가져올 때까지 기다려야 하므로 서비스품질이 저하된다.

STON이 제안하는 분산캐시는 3 Tier구조의 분산캐시이다. 

우선 클라이언트와 직접 연결되는 Child(=Edge)서버부터 이야기를 시작해 보자. 
HTTP는 한번 연결을 맺은 서버와 여러번의 HTTP 트랜잭션을 수행하는 특성을 가진다. 
웹 페이지의 경우 데이터 전송보다 DNS Query와 소켓 연결에 더 많은 시간이 소요된다. 
클라이언트는 자신이 연결된 서버로부터 모든 데이터를 제공받을 때 가장 빠르다. 
결국 Child는 항상 가장 Hot한(=많이 접근되는) 컨텐츠를 캐싱하고 있어야 한다. 
이것이 빠른 반응성을 보장하는 방법이다. 

사용자들이 가장 많이 접근하는 페이지들은 대부분 Child에 캐싱되어 있을 것이며, 
어느 캐시서버에 접속하더라도 해당 페이지를 빠르게 서비스받을 수 있다.
우선 Child는 Hot한 컨텐츠를 항상 캐싱하고 있어야 한다는데는 이견이 없다. 

예를 들어 원본서버의 전체 컨텐츠가 2,000만개이고 한대의 캐시서버가 1,000만개의 컨텐츠를 
캐싱할 수 있다고 가정해보자. 
2 Tier구성일 경우 Child서버는 캐싱하지 못한 1,000만개를 캐싱하기 위해 
항상 원본서버로 요청을 보낸다. 
서비스가 커질수록 원본서버가 많은 부하를 받게 된다. 

이런 단점을 극복하기 위해 Child와 원본서버 사이에 캐시서버를 두면 효과적이다. 
언뜻 큰 의미가 없어 보이기도 한다.
하지만 클라이언트가 요청을 분산해서 보내면 이야기가 달라진다. 

Child와 원본서버 사이에 Parent를 2대 투입한다. 
Parent한대당 1,000만개를 캐싱할 수 있다. 
모든 Chlid들은 해쉬 알고리즘에 의해서 홀수 컨텐츠는 왼쪽 서버에, 
짝수 컨텐츠는 오른쪽 서버로 요청할 수 있다. 
이렇게 설정하면 Parent캐시서버의 집중도가 매우 높아지는 효과가 발생한다. 
결국 원본서버의 부하없이 모든 컨텐츠를 캐시서버팜 안에 캐싱할 수 있을 뿐만 아니라 
간단히 Child서버를 증설하여 부담없는 Topology를 구성할 수 있다.

.. figure:: img/faq_3tierdist.jpg
   :align: center
      
   콘텐츠 분산캐시

분산캐시는 Child서버의 가상호스트에 설정한다. ::

    <OriginOptions>
        <Distribution>OFF</Distribution>    
    </OriginOptions>
    
-  ``<Distribution>`` 원본서버 분산모드를 설정한다.

   - ``OFF (기본)`` ``<BalanceMode>`` 에 따라 동작한다.
   
   - ``ON`` 콘텐츠를 분산하여 요청한다. ``<BalanceMode>`` 는 무시된다. 

원본 컨텐츠가 더 늘어나면 Parent서버를 한대 더 투입만 하면된다. 
여전히 Child는 Hot 컨텐츠 위주로 캐싱하며 가장 빠르고 신뢰할 수 있는 경로로 
Long-Tail컨텐츠를 캐싱할 수 있다. 
Parent서버에 장애가 발생하면 Child들은 장애서버를 배제하고 컨텐츠를 다시 분산한다. 
Standby서버가 있다면 장애서버 위치에 Standby서버를 위치시켜 다른 Parent서버가 
영향받지 않게 한다.

